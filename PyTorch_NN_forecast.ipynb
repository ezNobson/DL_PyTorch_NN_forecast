{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:21.655203Z",
     "start_time": "2025-07-09T14:30:21.648296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!pip install torch\n",
    "#!pip install torchvision"
   ],
   "id": "47f44eb035cba62a",
   "outputs": [],
   "execution_count": 304
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:21.668280Z",
     "start_time": "2025-07-09T14:30:21.655203Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torchvision"
   ],
   "outputs": [],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:21.739238Z",
     "start_time": "2025-07-09T14:30:21.732272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "dffc3390dab0db3f",
   "outputs": [],
   "execution_count": 306
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.395135Z",
     "start_time": "2025-07-09T14:30:21.804165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"preprocessed_data.csv\")\n",
    "df.describe()"
   ],
   "id": "d66432c868aecd43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         total_load  latitude     longitude   temperature          hour  \\\n",
       "count  43848.000000   43848.0  4.384800e+04  43848.000000  43848.000000   \n",
       "mean   19201.408502      52.0  1.955556e+01      9.957783     11.500000   \n",
       "std     3246.750377       0.0  1.670150e-11      8.275852      6.922265   \n",
       "min    10769.000000      52.0  1.955556e+01    -17.130000      0.000000   \n",
       "25%    16555.000000      52.0  1.955556e+01      3.300000      5.750000   \n",
       "50%    19252.000000      52.0  1.955556e+01      9.324444     11.500000   \n",
       "75%    21664.000000      52.0  1.955556e+01     16.307778     17.250000   \n",
       "max    28304.000000      52.0  1.955556e+01     32.534444     23.000000   \n",
       "\n",
       "       day_of_week_num  day_of_week_sin  day_of_week_cos      hour_sin  \\\n",
       "count     43848.000000     4.384800e+04     4.384800e+04  4.384800e+04   \n",
       "mean          3.000000    -2.139018e-17    -1.920254e-17 -1.361193e-17   \n",
       "std           2.000023     7.071148e-01     7.071148e-01  7.071148e-01   \n",
       "min           0.000000    -9.749279e-01    -9.009689e-01 -1.000000e+00   \n",
       "25%           1.000000    -7.818315e-01    -9.009689e-01 -7.071068e-01   \n",
       "50%           3.000000     0.000000e+00    -2.225209e-01  6.123234e-17   \n",
       "75%           5.000000     7.818315e-01     6.234898e-01  7.071068e-01   \n",
       "max           6.000000     9.749279e-01     1.000000e+00  1.000000e+00   \n",
       "\n",
       "           hour_cos  ...  next_load_14  next_load_15  next_load_16  \\\n",
       "count  4.384800e+04  ...  43848.000000  43848.000000  43848.000000   \n",
       "mean  -5.534910e-17  ...  19201.688538  19201.663747  19201.636996   \n",
       "std    7.071148e-01  ...   3246.286491   3246.316779   3246.349109   \n",
       "min   -1.000000e+00  ...  10769.000000  10769.000000  10769.000000   \n",
       "25%   -7.071068e-01  ...  16555.000000  16555.000000  16555.000000   \n",
       "50%   -6.123234e-17  ...  19252.000000  19252.000000  19252.000000   \n",
       "75%    7.071068e-01  ...  21664.000000  21664.000000  21664.000000   \n",
       "max    1.000000e+00  ...  28304.000000  28304.000000  28304.000000   \n",
       "\n",
       "       next_load_17  next_load_18  next_load_19  next_load_20  next_load_21  \\\n",
       "count  43848.000000  43848.000000  43848.000000  43848.000000  43848.000000   \n",
       "mean   19201.583379  19201.522692  19201.460203  19201.396255  19201.338533   \n",
       "std     3246.404176   3246.463605   3246.524035   3246.585244   3246.642919   \n",
       "min    10769.000000  10769.000000  10769.000000  10769.000000  10769.000000   \n",
       "25%    16555.000000  16555.000000  16554.812500  16554.187500  16554.000000   \n",
       "50%    19252.000000  19252.000000  19252.000000  19252.000000  19252.000000   \n",
       "75%    21664.000000  21664.000000  21664.000000  21664.000000  21664.000000   \n",
       "max    28304.000000  28304.000000  28304.000000  28304.000000  28304.000000   \n",
       "\n",
       "       next_load_22  next_load_23  \n",
       "count  43848.000000  43848.000000  \n",
       "mean   19201.297140  19201.272259  \n",
       "std     3246.688841   3246.719218  \n",
       "min    10769.000000  10769.000000  \n",
       "25%    16554.000000  16554.000000  \n",
       "50%    19252.000000  19252.000000  \n",
       "75%    21664.000000  21664.000000  \n",
       "max    28304.000000  28304.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_load</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week_num</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>next_load_14</th>\n",
       "      <th>next_load_15</th>\n",
       "      <th>next_load_16</th>\n",
       "      <th>next_load_17</th>\n",
       "      <th>next_load_18</th>\n",
       "      <th>next_load_19</th>\n",
       "      <th>next_load_20</th>\n",
       "      <th>next_load_21</th>\n",
       "      <th>next_load_22</th>\n",
       "      <th>next_load_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.0</td>\n",
       "      <td>4.384800e+04</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>4.384800e+04</td>\n",
       "      <td>4.384800e+04</td>\n",
       "      <td>4.384800e+04</td>\n",
       "      <td>4.384800e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "      <td>43848.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19201.408502</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>9.957783</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.139018e-17</td>\n",
       "      <td>-1.920254e-17</td>\n",
       "      <td>-1.361193e-17</td>\n",
       "      <td>-5.534910e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>19201.688538</td>\n",
       "      <td>19201.663747</td>\n",
       "      <td>19201.636996</td>\n",
       "      <td>19201.583379</td>\n",
       "      <td>19201.522692</td>\n",
       "      <td>19201.460203</td>\n",
       "      <td>19201.396255</td>\n",
       "      <td>19201.338533</td>\n",
       "      <td>19201.297140</td>\n",
       "      <td>19201.272259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3246.750377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.670150e-11</td>\n",
       "      <td>8.275852</td>\n",
       "      <td>6.922265</td>\n",
       "      <td>2.000023</td>\n",
       "      <td>7.071148e-01</td>\n",
       "      <td>7.071148e-01</td>\n",
       "      <td>7.071148e-01</td>\n",
       "      <td>7.071148e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3246.286491</td>\n",
       "      <td>3246.316779</td>\n",
       "      <td>3246.349109</td>\n",
       "      <td>3246.404176</td>\n",
       "      <td>3246.463605</td>\n",
       "      <td>3246.524035</td>\n",
       "      <td>3246.585244</td>\n",
       "      <td>3246.642919</td>\n",
       "      <td>3246.688841</td>\n",
       "      <td>3246.719218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10769.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>-17.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.749279e-01</td>\n",
       "      <td>-9.009689e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "      <td>10769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16555.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.818315e-01</td>\n",
       "      <td>-9.009689e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>16555.000000</td>\n",
       "      <td>16555.000000</td>\n",
       "      <td>16555.000000</td>\n",
       "      <td>16555.000000</td>\n",
       "      <td>16555.000000</td>\n",
       "      <td>16554.812500</td>\n",
       "      <td>16554.187500</td>\n",
       "      <td>16554.000000</td>\n",
       "      <td>16554.000000</td>\n",
       "      <td>16554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19252.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>9.324444</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.225209e-01</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-6.123234e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "      <td>19252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21664.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>16.307778</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>6.234898e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "      <td>21664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28304.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.955556e+01</td>\n",
       "      <td>32.534444</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.749279e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "      <td>28304.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 307
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.519326Z",
     "start_time": "2025-07-09T14:30:22.501015Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "24ed2b8ab8872b71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43848 entries, 0 to 43847\n",
      "Data columns (total 58 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   time             43848 non-null  object \n",
      " 1   total_load       43848 non-null  float64\n",
      " 2   latitude         43848 non-null  float64\n",
      " 3   longitude        43848 non-null  float64\n",
      " 4   temperature      43848 non-null  float64\n",
      " 5   date             43848 non-null  object \n",
      " 6   hour             43848 non-null  int64  \n",
      " 7   day_of_week      43848 non-null  object \n",
      " 8   day_of_week_num  43848 non-null  int64  \n",
      " 9   day_of_week_sin  43848 non-null  float64\n",
      " 10  day_of_week_cos  43848 non-null  float64\n",
      " 11  hour_sin         43848 non-null  float64\n",
      " 12  hour_cos         43848 non-null  float64\n",
      " 13  day_of_year      43848 non-null  int64  \n",
      " 14  days_in_year     43848 non-null  int64  \n",
      " 15  day_of_year_sin  43848 non-null  float64\n",
      " 16  day_of_year_cos  43848 non-null  float64\n",
      " 17  load-1           43848 non-null  float64\n",
      " 18  temp_t-1         43848 non-null  float64\n",
      " 19  load-2           43848 non-null  float64\n",
      " 20  temp_t-2         43848 non-null  float64\n",
      " 21  load-3           43848 non-null  float64\n",
      " 22  temp_t-3         43848 non-null  float64\n",
      " 23  load-22          43848 non-null  float64\n",
      " 24  temp_t-22        43848 non-null  float64\n",
      " 25  load-23          43848 non-null  float64\n",
      " 26  temp_t-23        43848 non-null  float64\n",
      " 27  load-24          43848 non-null  float64\n",
      " 28  temp_t-24        43848 non-null  float64\n",
      " 29  load-25          43848 non-null  float64\n",
      " 30  temp_t-25        43848 non-null  float64\n",
      " 31  load-26          43848 non-null  float64\n",
      " 32  temp_t-26        43848 non-null  float64\n",
      " 33  mean_t_3         43848 non-null  float64\n",
      " 34  mean_t_5         43848 non-null  float64\n",
      " 35  next_load_1      43848 non-null  float64\n",
      " 36  next_load_2      43848 non-null  float64\n",
      " 37  next_load_3      43848 non-null  float64\n",
      " 38  next_load_4      43848 non-null  float64\n",
      " 39  next_load_5      43848 non-null  float64\n",
      " 40  next_load_6      43848 non-null  float64\n",
      " 41  next_load_7      43848 non-null  float64\n",
      " 42  next_load_8      43848 non-null  float64\n",
      " 43  next_load_9      43848 non-null  float64\n",
      " 44  next_load_10     43848 non-null  float64\n",
      " 45  next_load_11     43848 non-null  float64\n",
      " 46  next_load_12     43848 non-null  float64\n",
      " 47  next_load_13     43848 non-null  float64\n",
      " 48  next_load_14     43848 non-null  float64\n",
      " 49  next_load_15     43848 non-null  float64\n",
      " 50  next_load_16     43848 non-null  float64\n",
      " 51  next_load_17     43848 non-null  float64\n",
      " 52  next_load_18     43848 non-null  float64\n",
      " 53  next_load_19     43848 non-null  float64\n",
      " 54  next_load_20     43848 non-null  float64\n",
      " 55  next_load_21     43848 non-null  float64\n",
      " 56  next_load_22     43848 non-null  float64\n",
      " 57  next_load_23     43848 non-null  float64\n",
      "dtypes: float64(51), int64(4), object(3)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "execution_count": 308
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.609299Z",
     "start_time": "2025-07-09T14:30:22.586363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['date'] = pd.to_datetime(df['time'])\n",
    "df['date'].info()"
   ],
   "id": "2cfa9f61dea754e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 43848 entries, 0 to 43847\n",
      "Series name: date\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "43848 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 342.7 KB\n"
     ]
    }
   ],
   "execution_count": 309
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.684608Z",
     "start_time": "2025-07-09T14:30:22.680447Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader",
   "id": "a6bd31a88d137ac3",
   "outputs": [],
   "execution_count": 310
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.837558Z",
     "start_time": "2025-07-09T14:30:22.827392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PowerLoadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.x_y(self.df.iloc[idx])\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def x_y(row):\n",
    "        feature_cols = ['load-1', 'load-2', 'load-3', 'load-22', 'load-23', 'load-24', 'load-25', 'load-26', 'mean_t_3',\n",
    "                        'mean_t_5', 'day_of_week_sin', 'day_of_week_cos', 'hour_sin', 'hour_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "        target_cols = ['total_load'] + [f'next_load_{i}' for i in range(1, 24)]\n",
    "        X = row[feature_cols].values.astype('float32')\n",
    "        y = row[target_cols].values.astype('float32')\n",
    "        return X, y\n",
    "    "
   ],
   "id": "c393e33151751d59",
   "outputs": [],
   "execution_count": 311
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:22.929134Z",
     "start_time": "2025-07-09T14:30:22.846867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = df[df['date'].dt.year < 2024]\n",
    "test_df = df[df['date'].dt.year == 2024]"
   ],
   "id": "9bdfb1877491da62",
   "outputs": [],
   "execution_count": 312
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.005636Z",
     "start_time": "2025-07-09T14:30:23.000441Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.preprocessing import MinMaxScaler",
   "id": "5c7fa295d2a2b636",
   "outputs": [],
   "execution_count": 313
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.150079Z",
     "start_time": "2025-07-09T14:30:23.071492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "temp_cols = ['mean_t_3', 'mean_t_5']\n",
    "other_cols = ['load-1', 'load-2', 'load-3', 'load-22', 'load-23', 'load-24', 'load-25', 'load-26',\n",
    "              'day_of_week_sin', 'day_of_week_cos', 'hour_sin', 'hour_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "\n",
    "scaler_temp = MinMaxScaler(feature_range=(-1, 1)).fit(train_df[temp_cols])\n",
    "train_df[temp_cols] = scaler_temp.transform(train_df[temp_cols])\n",
    "test_df[temp_cols] = scaler_temp.transform(test_df[temp_cols])\n",
    "\n",
    "for col in other_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_df[[col]])\n",
    "    train_df[col] = scaler.transform(train_df[[col]])\n",
    "    test_df[col] = scaler.transform(test_df[[col]])\n",
    "    \n",
    "target_cols = ['total_load'] + [f'next_load_{i}' for i in range(1, 24)]\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_df[target_cols])\n",
    "train_df[target_cols] = scaler_y.transform(train_df[target_cols])\n",
    "test_df[target_cols] = scaler_y.transform(test_df[target_cols])\n"
   ],
   "id": "fd1e7e5898d2485e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[temp_cols] = scaler_temp.transform(train_df[temp_cols])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[temp_cols] = scaler_temp.transform(test_df[temp_cols])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[col] = scaler.transform(train_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = scaler.transform(test_df[[col]])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[target_cols] = scaler_y.transform(train_df[target_cols])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10028\\2206988589.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[target_cols] = scaler_y.transform(test_df[target_cols])\n"
     ]
    }
   ],
   "execution_count": 314
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.239543Z",
     "start_time": "2025-07-09T14:30:23.215982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = PowerLoadDataset(train_df)\n",
    "test_dataset = PowerLoadDataset(test_df)"
   ],
   "id": "a8294b7b7e046c3a",
   "outputs": [],
   "execution_count": 315
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.313356Z",
     "start_time": "2025-07-09T14:30:23.303393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_train, labels_train = train_dataset[0]\n",
    "features_test, labels_test = test_dataset[0]\n",
    "print(f\"TRAIN: Shape of features - {features_train.shape}, Shape of labels - {labels_train.shape}\")\n",
    "print(f\"TEST: Shape of features - {features_test.shape}, Shape of labels - {labels_test.shape}\")"
   ],
   "id": "5a824c4b81e245d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Shape of features - torch.Size([16]), Shape of labels - torch.Size([24])\n",
      "TEST: Shape of features - torch.Size([16]), Shape of labels - torch.Size([24])\n"
     ]
    }
   ],
   "execution_count": 316
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.390848Z",
     "start_time": "2025-07-09T14:30:23.384624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Number of samples in test dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in train dataset: {len(test_dataset)}\")\n",
    "\n",
    "combined_samples_number = len(train_dataset) + len(test_dataset)\n",
    "print(df.shape[0])\n",
    "print(combined_samples_number == df.shape[0])"
   ],
   "id": "5afdbc21ef0a6f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test dataset: 35064\n",
      "Number of samples in train dataset: 8784\n",
      "43848\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 317
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.468241Z",
     "start_time": "2025-07-09T14:30:23.459935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "95de823ef16c6e50",
   "outputs": [],
   "execution_count": 318
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.553919Z",
     "start_time": "2025-07-09T14:30:23.531526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features, labels = next(iter(dataloader_train))\n",
    "print(f\"Features shape: {features.shape}, labels shape: {labels.shape} \")"
   ],
   "id": "c75c0535f231f006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([32, 16]), labels shape: torch.Size([32, 24]) \n"
     ]
    }
   ],
   "execution_count": 319
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.627209Z",
     "start_time": "2025-07-09T14:30:23.621145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimplePerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 25)\n",
    "        self.fc2 = nn.Linear(25, 24)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "a44480da24811d1f",
   "outputs": [],
   "execution_count": 320
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.696382Z",
     "start_time": "2025-07-09T14:30:23.689894Z"
    }
   },
   "cell_type": "code",
   "source": "Perceptron = SimplePerceptron()",
   "id": "9ee4a72f1047902d",
   "outputs": [],
   "execution_count": 321
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "11f4f0506744d69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.770050Z",
     "start_time": "2025-07-09T14:30:23.764528Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.optim as optim",
   "id": "7981d1ffb213efd6",
   "outputs": [],
   "execution_count": 322
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.837827Z",
     "start_time": "2025-07-09T14:30:23.833052Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = optim.Adam(Perceptron.parameters(), lr=0.0005)",
   "id": "c3a5e5b454a5d1c7",
   "outputs": [],
   "execution_count": 323
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.911930Z",
     "start_time": "2025-07-09T14:30:23.907762Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.MSELoss()",
   "id": "8fd43496ff9ea07",
   "outputs": [],
   "execution_count": 324
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our metric will be mape",
   "id": "65cfa6c54955631e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:23.978551Z",
     "start_time": "2025-07-09T14:30:23.975336Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "2160964f8bc36719",
   "outputs": [],
   "execution_count": 325
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:24.049081Z",
     "start_time": "2025-07-09T14:30:24.042311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return (torch.abs((y_true[mask] - y_pred[mask]) / (y_true[mask] + 1e-8))).mean() * 100"
   ],
   "id": "249587c29829627f",
   "outputs": [],
   "execution_count": 326
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:39:33.219131Z",
     "start_time": "2025-07-09T14:30:24.118064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    running_mape = 0.0\n",
    "    for features, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Perceptron(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "        outputs_orig = scaler_y.inverse_transform(outputs_np)\n",
    "        labels_orig = scaler_y.inverse_transform(labels_np)\n",
    "        \n",
    "        batch_mape = np.mean(np.abs((labels_orig - outputs_orig) / (labels_orig + 1e-8))) * 100\n",
    "        running_mape += batch_mape\n",
    "        \n",
    "    avg_loss = running_loss / len(dataloader_train)\n",
    "    avg_mape = running_mape / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, MAPE={avg_mape:.2f}%\")"
   ],
   "id": "1d61ae0d95018065",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.0447, MAPE=14.85%\n",
      "Epoch 2: Loss=0.0221, MAPE=11.32%\n",
      "Epoch 3: Loss=0.0157, MAPE=9.06%\n",
      "Epoch 4: Loss=0.0133, MAPE=8.03%\n",
      "Epoch 5: Loss=0.0124, MAPE=7.66%\n",
      "Epoch 6: Loss=0.0118, MAPE=7.47%\n",
      "Epoch 7: Loss=0.0115, MAPE=7.33%\n",
      "Epoch 8: Loss=0.0111, MAPE=7.21%\n",
      "Epoch 9: Loss=0.0108, MAPE=7.10%\n",
      "Epoch 10: Loss=0.0105, MAPE=6.98%\n",
      "Epoch 11: Loss=0.0102, MAPE=6.86%\n",
      "Epoch 12: Loss=0.0099, MAPE=6.74%\n",
      "Epoch 13: Loss=0.0096, MAPE=6.61%\n",
      "Epoch 14: Loss=0.0093, MAPE=6.48%\n",
      "Epoch 15: Loss=0.0091, MAPE=6.37%\n",
      "Epoch 16: Loss=0.0089, MAPE=6.27%\n",
      "Epoch 17: Loss=0.0087, MAPE=6.18%\n",
      "Epoch 18: Loss=0.0085, MAPE=6.11%\n",
      "Epoch 19: Loss=0.0084, MAPE=6.05%\n",
      "Epoch 20: Loss=0.0083, MAPE=5.99%\n"
     ]
    }
   ],
   "execution_count": 327
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Evaluation\n",
   "id": "bd636ab162aac8fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:41:04.599385Z",
     "start_time": "2025-07-09T14:40:59.489917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Perceptron.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "total_mape = 0.0\n",
    "n_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "        outputs = Perceptron(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "        outputs_orig = scaler_y.inverse_transform(outputs_np)\n",
    "        labels_orig = scaler_y.inverse_transform(labels_np)\n",
    "        \n",
    "        batch_mape = np.mean(np.abs((labels_orig - outputs_orig) / (labels_orig + 1e-8))) * 100\n",
    "        total_mape += batch_mape\n",
    "        n_batches += 1\n",
    "\n",
    "avg_loss = total_loss / n_batches\n",
    "avg_mape = total_mape / n_batches\n",
    "print(f\"Test MSE: {avg_loss:.4f}, Test MAPE: {avg_mape:.2f}%\")"
   ],
   "id": "54f5749ca9feb161",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0109, Test MAPE: 7.34%\n"
     ]
    }
   ],
   "execution_count": 329
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:39:38.110780Z",
     "start_time": "2025-07-09T14:39:38.099433Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f646d746860e077c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
